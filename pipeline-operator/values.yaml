# replicaCount -- (int) Number of pipeline-operator pods to load balance between
replicaCount: 1

# imagePullSecrets -- Image pull secrets if private images are used
imagePullSecrets: []

# nameOverride -- Manually set metadata for the Release. Defaults to .Chart.Name
nameOverride: ""

# fullnameOverride -- Defaults to .Release.Name-.Chart.Name unless .Release.Name contains "algorun-pipeline-operator"
fullnameOverride: ""

# image -- Set the image and tag for the pipeline operator
image:
  repository: algohub/pipeline-operator
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart version.
  tag: "eb2896135958feb9c2f7b45efd79ad76ea8ccfef"

algoRunnerImage:
  # algoRunnerImage.repository -- Set the default image and tag that will be used for the algo-runner sidecar.
  # The algoRunnerImage may be overridden by a pipeline deployment
  repository: algohub/algo-runner
  # algoRunnerImage.pullPolicy -- The algo-runner image pull policy
  pullPolicy: IfNotPresent
  # algoRunnerImage.tag -- The algo-runner image tag
  tag: "240153868a5b21207b61270762bffc978615964a"


endpointImage:
  # endpointImage.repository -- Set the default image and tag that will be used for the pipeline endpoint gateway.
  # The endpointImage may be overridden by a pipeline deployment
  repository: algohub/pipeline-endpoint
  # endpointImage.pullPolicy -- The pipeline endpoint image pull policy
  pullPolicy: IfNotPresent
  # endpointImage.tag -- The pipeline endpoint image tag
  tag: "517fcd1c9c2815b537481eeb2389c9fe1489beb0"

eventHookImage:
  # eventHookImage.repository -- Set the default image and tag that will be used for the pipeline hook runner.
  # The eventHookImage may be overridden by a pipeline deployment
  repository: algohub/event-hook-runner
  # eventHookImage.pullPolicy -- The event hook runner image pull policy
  pullPolicy: IfNotPresent
  # eventHookImage.tag -- The event hook runner image tag
  tag: "5ae767f855bf45a102a5327f7685cc89d4a45d8d"

# Http webhook notifications can be sent to a url with status changes 
notifications:
  # notifications.enabled -- Enable webhook notifications to be sent for pipeline status changes
  enabled: false
  # notifications.url -- Url to send status event notifications to
  url: 

scope: 
  # scope.type -- If set to "cluster", the pipeline operator will manage kafka and ambassador resources in any namespace and create Cluster RBAC if rbac.enabled: true 
  # If set to "namespace" (Not recommended) the ambassador, kafka operator and pipeline operator must be installed in the same namespace.
  type: cluster
  # scope.watchNamespace -- The namespace to watch for new pipeline deployments. Default "" watches all namespaces.
  watchNamespace: ""

storage:
  # storage.enabled -- Enable storing algo output data to S3 compatible buckets
  enabled: true
  # storage.storageSecret -- The storage connection string secret. This secret must contain a connection string in the format:
  # https://username:password@s3host:port
  # The secret name can use a template to enable each deployment to be configured for a different S3 connection.
  # Ex. "storage-{deploymentowner}-{deploymentname}"
  storageSecret: "storage-connection"
  # storage.storageSecretKey -- The key (file name) for the connection string within the secret
  storageSecretKey: "connection-string"
  # storage.region -- The region for storage buckets. Default for minio is "us-east-1"
  # Amazon regions ref: https://docs.aws.amazon.com/general/latest/gr/rande.html
  # Google locations ref: https://cloud.google.com/storage/docs/locations
  region: "us-east-1"
  # storage.bucketName -- The S3 bucket name.
  # The bucket name can use a template to enable each deployment to be configured to save data to different buckets.
  bucketName: "{deploymentowner}-{deploymentname}"

kafka:
  # kafka.operatorType -- Currently only the strimzi kafka operator is supported
  operatorType: strimzi
  # kafka.namespace -- The namespace the kafka operator is installed on
  namespace: kafka
  # kafka.clusterName -- The name of the kafka cluster (as defined for the kafka operator)
  clusterName: kafka
  tls:
    # kafka.tls.enabled -- Enable communication over TLS to the kafka brokers 
    enabled: true
    # kafka.tls.caSecretName -- Name of the secret that contains the certificate authority X509 cert
    caSecretName: kafka-cluster-ca-cert
    # kafka.tls.caCertSecretKey -- The key (file name) within the secret
    caCertSecretKey: ca.crt
  auth: 
    # kafka.auth.type -- Enable communication over TLS to the kafka brokers 
    type: ""
    # kafka.auth.authSecretName -- If auth type "tls" then the name of the secret that contains the client X509 cert
    # The name can use a template as certs can be generated dynamically by the kafka operator
    # If auth type "scram-sha-512" or "plain" then the name of the secret that contains the password
    authSecretName: "{kafkaClusterName}-{deploymentowner}-{deploymentname}"
    # kafka.auth.authCertSecretKey -- The key (file name) for the cert within the secret
    authCertSecretKey: user.crt
    # kafka.auth.authKeySecretKey -- The key (file name) for the private key within the secret
    authKeySecretKey: user.key

    # kafka.auth.passwordSecretKey -- The key (file name) for the password within the secret
    passwordSecretKey: 
  # auth: 
  #   type: scram-sha-512
  #   username: 
  #   authSecretName: 
  #   passwordSecretKey: 
  # auth: 
  #   type: plain
  #   username: 
  #   authSecretName: 
  #   passwordSecretKey: 

# env -- Additional container environment variables
env: {}
  # Manually set the name of the operator
  # OPERATOR_NAME: "pipeline-operator"

rbac:
  # rbac.create -- Specifies whether RBAC resources should be created
  create: true
  # rbac.podSecurityPolicies -- podSecurityPolicies to be added
  podSecurityPolicies: []
  # rbac.nameOverride -- Name of the RBAC resources defaults to the name of the release.
  # Set nameOverride when installing pipeline operator with cluster-wide scope in
  # different namespaces with the same release name to avoid conflicts.
  nameOverride:

metrics:
  # metrics.enabled -- Enable metrics collection with the prometheus operator
  enabled: true
  # metrics.prometheusOperatorNamespace -- Prometheus operator namespace to create grafana dashboard and data source resources in
  prometheusOperatorNamespace: "prometheus-operator"
  # metrics.createDashboards -- Install grafana dashboards and data sources. The prometheus operator must be install with the grafana sidecar enabled.
  createDashboards: true

  # metrics.serviceMonitorNamespace -- The serviceMonitorNamespace sets the namespace the servicemonitor will be created in.
  # By default, it is created in the release namespace. If necessary, set the namespace the prometheus operator is watching for service monitors.
  serviceMonitorNamespace: 

  pipelineOperatorServiceMonitor:
    # metrics.pipelineOperatorServiceMonitor.enabled -- If the prometheus operator is installed in your cluster, set to true to create a Service Monitor Entry
    enabled: true
    # metrics.pipelineOperatorServiceMonitor.namespace -- Specify the namespace in which the serviceMonitor resource will be created
    namespace:
    # metrics.pipelineOperatorServiceMonitor.interval -- The interval at which metrics should be scraped
    interval: 30s
    # metrics.pipelineOperatorServiceMonitor.scrapeTimeout -- Specify the timeout after which the scrape is ended
    scrapeTimeout: 30s
    # metrics.pipelineOperatorServiceMonitor.relabellings -- Specify Metric Relabellings to add to the scrape endpoint
    relabellings:
    # metrics.pipelineOperatorServiceMonitor.honorLabels -- Specify honorLabels parameter to add the scrape endpoint
    honorLabels: false
    # metrics.pipelineOperatorServiceMonitor.release -- Specify the release for ServiceMonitor. Sometimes it should be custom for prometheus operator to work
    release:
    # metrics.pipelineOperatorServiceMonitor.additionalLabels -- Used to pass Labels that are used by the Prometheus installed in your cluster to select Service Monitors to work with
    # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
    additionalLabels: {}

  algoServiceMonitor:
    # metrics.algoServiceMonitor.enabled -- If the prometheus operator is installed in your cluster, set to true to create a Service Monitor Entry
    enabled: true
    # metrics.algoServiceMonitor.namespace -- Specify the namespace in which the serviceMonitor resource will be created
    namespace:
    # metrics.algoServiceMonitor.interval -- The interval at which metrics should be scraped
    interval: 30s
    # metrics.algoServiceMonitor.scrapeTimeout -- Specify the timeout after which the scrape is ended
    scrapeTimeout: 30s
    # metrics.algoServiceMonitor.relabellings -- Specify Metric Relabellings to add to the scrape endpoint
    relabellings:
    # metrics.algoServiceMonitor.honorLabels -- Specify honorLabels parameter to add the scrape endpoint
    honorLabels: false
    # metrics.algoServiceMonitor.release -- Specify the release for ServiceMonitor. Sometimes it should be custom for prometheus operator to work
    release:
    # metrics.algoServiceMonitor.additionalLabels -- Used to pass Labels that are used by the Prometheus installed in your cluster to select Service Monitors to work with
    # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
    additionalLabels: {}
  
  dataConnectorServiceMonitor:
    # metrics.dataConnectorServiceMonitor.enabled -- If the prometheus operator is installed in your cluster, set to true to create a Service Monitor Entry
    enabled: true
    # metrics.dataConnectorServiceMonitor.namespace -- Specify the namespace in which the serviceMonitor resource will be created
    namespace:
    # metrics.dataConnectorServiceMonitor.interval -- The interval at which metrics should be scraped
    interval: 30s
    # metrics.dataConnectorServiceMonitor.scrapeTimeout -- Specify the timeout after which the scrape is ended
    scrapeTimeout: 30s
    # metrics.dataConnectorServiceMonitor.relabellings -- Specify Metric Relabellings to add to the scrape endpoint
    relabellings:
    # metrics.dataConnectorServiceMonitor.honorLabels -- Specify honorLabels parameter to add the scrape endpoint
    honorLabels: false
    # metrics.dataConnectorServiceMonitor.release -- Specify the release for ServiceMonitor. Sometimes it should be custom for prometheus operator to work
    release:
    # metrics.dataConnectorServiceMonitor.additionalLabels -- Used to pass Labels that are used by the Prometheus installed in your cluster to select Service Monitors to work with
    # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
    additionalLabels: {}

  endpointServiceMonitor:
    # metrics.endpointServiceMonitor.enabled -- If the prometheus operator is installed in your cluster, set to true to create a Service Monitor Entry
    enabled: true
    # metrics.endpointServiceMonitor.namespace -- Specify the namespace in which the serviceMonitor resource will be created
    namespace:
    # metrics.endpointServiceMonitor.interval -- The interval at which metrics should be scraped
    interval: 30s
    # metrics.endpointServiceMonitor.scrapeTimeout -- Specify the timeout after which the scrape is ended
    scrapeTimeout: 30s
    # metrics.endpointServiceMonitor.relabellings -- Specify Metric Relabellings to add to the scrape endpoint
    relabellings:
    # metrics.endpointServiceMonitor.honorLabels -- Specify honorLabels parameter to add the scrape endpoint
    honorLabels: false
    # metrics.endpointServiceMonitor.release -- Specify the release for ServiceMonitor. Sometimes it should be custom for prometheus operator to work
    release:
    # metrics.endpointServiceMonitor.additionalLabels -- Used to pass Labels that are used by the Prometheus installed in your cluster to select Service Monitors to work with
    # ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
    additionalLabels: {}

serviceAccount:
  # serviceAccount.create -- Specifies whether a service account should be created
  create: true
  # serviceAccount.annotations -- Annotations to add to the service account
  annotations: {}
  # serviceAccount.name -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# podAnnotations -- Additional annotations to add to the pod
podAnnotations: {}

# podSecurityContext -- Set security context for the pod
podSecurityContext: {}
  # fsGroup: 2000

# securityContext -- Set security context for the deployment
securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# resources -- Set the resource requests and limits
resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  # autoscaling.enabled -- Enable autoscaling using a HorizontalPodAutoscaler
  enabled: false
  # autoscaling.minReplicas -- Minimum replicas created by the HorizontalPodAutoscaler
  minReplicas: 1
  # autoscaling.maxReplicas -- Maximum replicas created by the HorizontalPodAutoscaler
  maxReplicas: 100
  # autoscaling.metrics -- Metrics for the HorizontalPodAutoscaler
  # ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics
  metrics:
  # - type: Resource
  #   resource:
  #     name: cpu
  #     targetAverageUtilization: 80
  # - type: Resource
  #   resource:
  #     name: memory
  #     targetAverageUtilization: 80

# nodeSelector -- Set the node selector. 
# ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
nodeSelector: {}

# tolerations -- Set the tolerations. 
# ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []

# affinity -- Set the affinity.
# ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
affinity: {}
